#!/usr/bin/env perl 

use strict;
use warnings;
use 5.014;

use Getopt::Long;
use Mojo::UserAgent;
use File::Path qw/ make_path /;
use File::Spec;
use Digest::SHA qw/ sha256_hex /;

GetOptions(
    'help|h'          => \(my $HELP),
    'dest|d=s'        => \(my $DEST = '/var/www/html'),
    'src|s=s'         => \(my $SRC = 'https://onvotar.garantiespelreferendum.com'),
    'connections|n=i' => \(my $CONNECTIONS = 10),
    'verbose|v+'      => \(my $VERBOSE = 0),
    'timeout|t=i'     => \(my $TIMEOUT = 5),
    'only-hash|H'     => \(my $ONLY_HASH = 0),
);

if( $HELP ) {
    print <<"EOH";
Usage: $0 [--dest path/to/destination] [--src https://onvotar.garantiespelreferendum.com]
Options:
    --dest
    --src
    --connections, -n  Number of parallel requests
EOH
    exit 1;
}

my @stack = ();
my %seen = ();
my %hashes = ();
my $running = 0;
my $ok = 0;
my $fail = 0;

my $ua = Mojo::UserAgent->new
    ->request_timeout($TIMEOUT)
    ->connect_timeout($TIMEOUT)
    ->inactivity_timeout(1);

sub process_response {
	my ($ua, $tx) = @_;
    my $res = $tx->result;
    my $url = $tx->req->url;

    $running--;

    if( $res->is_success ) {
        my $rel = $url;

        $rel = "$rel/index.html"
            if $rel =~ m#\/$#;

        unless( $rel =~ s#^$SRC## ) {
            say "External url retrieved: $rel. Redirected?";
            return;
        }

        my ($vol, $path, $file) = File::Spec->splitpath($rel);
        my $base = $url;
        $base =~ s#$file$##;

        unless( $ONLY_HASH ) {
            # Store file
            make_path("$DEST/$path") unless -d "$DEST/$path";
            open my $fh, '>', "$DEST/$path$file"
                or die "Cannoy open $DEST/$path$file: $!";
            print $fh $res->body;
            close $fh;
            say "[DONE] $url";
        }

        # Hash and store
        my $hash = sha256_hex( $res->body );
        $hashes{ "$path$file" } = $hash;
        say "[HASH] $hash $url"
            if $VERBOSE;

        $ok++;

        # Scrap HTML documents
        if( $res->headers->content_type =~ m#html# ) {
            my $dom = $res->dom;
            enqueue_links(
                $base,
                $dom->find('a')->map(sub { $_->attr("href")})->each,
                $dom->find('link')->map(sub { $_->attr("href")})->each,
                $dom->find('script')->map(sub { $_->attr("src")})->each,
                $dom->find('img')->map(sub { $_->attr("src")})->each,
            );
        } elsif( $res->headers->content_type =~ m#css# ) {
            enqueue_links(
                $base,
                $res->body =~ m#url\(([^\(]+)\)#g
            );
        }

    } else {
        say "[FAIL] $url (status ".$res->code.")";
        $fail++;
    }

    request_next();
}

sub request_next {
    my ($dir, $file);

    while( $running < $CONNECTIONS && @stack ) {
        my $next = shift @stack;

        say "[SCRAP] $next"
            if $VERBOSE;

        $ua->get($next => { 'User-Agent' => 'Importacio de dades per a mirrors' } => \&process_response);

        $running++;
    }
}

sub enqueue_links {
    my ($base, @links) = @_;

    push @stack, grep {
        # Not previously seen (and flag it now)
        !$seen{$_}++
    } map {
        # Yes, at least one url comes quoted T.T
        $_ =~ s#^['"](.*)['"]#$1#;
        # Relative paths with '.' seem to be broken
        $_ =~ s#^\.\/#\/#;
        # Make absolute
        $_ = $SRC.substr($_,1) if $_ =~ m#^\/#;
        $_ = "$base$_" unless $_ =~ m#^https?://#;
        # Kill query strings.. this should break most sites, but this one is suspiciously cooperative :shrug:
        $_ =~ s#\?.*$##;
        # Kill anchors too
        $_ =~ s/#.*$//;
        # Collapse relative paths
        $_ =~ s#/[^/\.]+/\.\./#/#g while( $_ =~ m#/[^/\.]+/\.\./# );
        # Return
        $_;
    } grep {
        # Tags missing attributes
        defined $_ &&
        # Unwanted protos or javascript hrefs
        $_ !~ m#^(mailto|javascript):# &&
        # Unwanted anchors
        $_ !~ m/^#/ &&
        # Absolute (external) URLs
        !( $_ =~ m#^[a-z]+:# && $_ !~ m#$SRC# )
    } @links;
}

$|=1;

$SRC = "$SRC/" if $SRC =~ m#^https?://[^/]+$#;

say "Going to scrap starting from $SRC...";
push @stack, $SRC;
request_next();
Mojo::IOLoop->start;

my $manifest = join "\n", map "$hashes{$_}:$_", sort { $a cmp $b } keys %hashes;
my $mhash = sha256_hex( $manifest );
open my $fh, '>', "$DEST/manifest.sha"
    or die "Failed to open manifest file for writing: $!";
print $fh $mhash."\n".$manifest;
close $fh;
say "Scrap hash: $mhash";
say "Stored manifest as: $DEST/manifest.sha";

say "Scrapped a total of @{[ scalar( keys %seen ) ]} ($ok ok, $fail fail) pages";

say "Finished!";


